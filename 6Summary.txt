 RESEARCH ARTICLE A systematic review of fuzzing based on machine learning techniques Yan Wang1, Peng Jia1, Luping Liu2, Cheng Huang1, Zhonglin Liu ID1  1 College of Cybersecurity Sichuan University, Chengdu, China, 2 College of Electronics and Information Engineering, Sichuan University, Chengdu, China   jungleforsa gmail.com Abstract Security vulnerabilities play a vital role in network security system. Finally, the capability of discovering vulnerabilities both traditional fuz  zers and machine learning based fuzzers is analyzed. The results depict that the introduc  tion of machine learning techniques can improve the performance of fuzzing. Introduction Vulnerabilities often refer to flaws or weaknesses in hardware, software, protocol implementa  tions, or system security policies that allow an attacker to access or compromise the system without authorization, and have become the root cause of the threats toward network security. https: doi.org 10.1371 journal. Machine learning has been used in the field of cybersecurity, and it has also been adopted by many studies for vulnerability detection  11 13 , including the applications in fuzzing  14  17 . Machine learning techniques used in fuzz testing will become one of the key points in the development of vulnerability detection techniques with the explosive growth of machine learning research. However, there is no systematic review of machine learning based fuzzing in the past few years. Some steps in the workflow, such as testcase filters, may not be needed in some fuzzers, but the PLOS ONE   https: doi.org 10.1371 journal.pone.0237749 August 18, 2020 2   37 PLOS ONE A systematic review of fuzzing based on machine learning techniques Fig 1. https: doi.org 10.1371 journal.pone.0237749.g001 general steps are similar. Finally, the analysts make the final con  firmation by debugging. PLOS ONE   https: doi.org 10.1371 journal.pone.0237749 August 18, 2020 3   37 PLOS ONE A systematic review of fuzzing based on machine learning techniques The limitations of fuzzing. However, these techniques still have certain limitations and disadvantages. However, there are many limitations on symbolic execution, such as path explosion  34 , environment interactions  35, 36 , mem  ory modeling  37, 38 , and parallel computing  39, 40 . Source material and search strategy To identify candidate papers, we first systematically examined all papers published in 15 top venues for computer security, software engineering, and artificial intelligence from 2010 to 2020: IEEE S P, ACM CCS, USENIX Security, NDSS, ACSAC, RAID, ESORICS, ASIACCS, PLOS ONE   https: doi.org 10.1371 journal.pone.0237749 August 18, 2020 4   37 PLOS ONE A systematic review of fuzzing based on machine learning techniques DIMVA, ICSE, FSE, ISSTA, ASE, MSR, and AAAI. For example, the following general search terms were used for identification of primary studies: Fuzzing AND machine learning, fuzzing AND neural network, fuzzer AND deep learning, fuzzing AND reinforcement learning, fuzzing AND embedding, fuzzing AND bayesian net  work, fuzzing AND decision tree, fuzzing AND support vector machine, fuzzing AND genetic algorithms, fuzzing AND random forest, and other similar combinations. Introduction of machine learning technology. Conference Workshop journal), data Machine learning is used in the steps of fuzzing Machine learning arithmetic applied in the study The value of the hyperparameter required for machine learning Pre processing methods for machine learning techniques in fuzzing Source of dataset used to train machine learning models Description of how the machine learning based fuzzer was evaluated Results of the evaluation The type of the fuzzer Remark about the study quality https: doi.org 10.1371 journal.pone.0237749.t001 PLOS ONE   https: doi.org 10.1371 journal.pone.0237749 August 18, 2020 5   37 PLOS ONE A systematic review of fuzzing based on machine learning techniques 2. Applying machine learning techniques to different fuzzing steps. Analysis of machine learning based fuzzing model. Performance evaluation of fuzzing model based on machine learning. Introduction of machine learning technology Machine learning acquires new knowledge or skills by learning from existing example data or experiences and optimizes the performance of the computer system itself automatically  83 . Machine learning tasks can be categorized into traditional machine learning, deep learning, and reinforcement learning. Traditional machine learning is divided into supervised learning, unsupervised learning, and semi supervised learning according to whether the input data is labeled or not and the amount of labeled data. https: doi.org 10.1371 journal.pone.0237749.g002 PLOS ONE   https: doi.org 10.1371 journal.pone.0237749 August 18, 2020 6   37 PLOS ONE Deep learning  84, 85  is an artificial neural network composed of multiple nonlinear pro  cessing units for data representation learning, which is a deeper extension of the machine learning algorithm. https: doi.org 10.1371 journal.pone.0237749.t002 A systematic review of fuzzing based on machine learning techniques PLOS ONE   https: doi.org 10.1371 journal.pone.0237749 August 18, 2020 7   37 PLOS ONE A systematic review of fuzzing based on machine learning techniques Current machine learning techniques have been widely used in statistical learning  87  pat  tern recognition  88 , data mining  89 , computer vision  90 , and natural language processing  91  In the field of cyberspace security, researchers have also used machine learning for scenar  ios such as malicious code detection  92, 93 , intrusion detection  94, 95 , spam and phishing classification  96, 97 , and log analysis  98, 99 . The application of machine learning technology on fuzz testing has also attracted the atten  tion of security researchers, and the reasons can be summarized as follows:   Many stages of the fuzzing process can be reviewed as classification problems, which are ideal for using machine learning algorithms to address, e.g., whether seed files and testcases are valid, the exploitability of crash, and which mutation operators to choose. Machine learn  ing techniques have relatively excellent abilities in dealing with classification problems. However, the prediction process of the machine learning model just consumes less time. Machine learning automatically learns gram  matical rules from a large pool of samples that conforms to the syntax specifications. Machine learning can be used to extract the hidden vulnerability features from existing numerous vulnerability related data, which can better guide the fuzzing process. For the first and second conditions, the fuzzing process is sufficient because the fuzzing can produce a large number of test samples and crash samples, which can be labeled during sample generation (e.g., whether code coverage increases during execution). The satisfaction of these prior conditions and the advantages of machine learning have led to rapid growth in the research of machine learning based fuzzing. Applying machine learning techniques to different fuzzing steps We classify these papers into five categories according to the problems they solved:   Seed file generation   Testcase generation   Testcase filtering   Mutation operator selection   Exploitability analysis PLOS ONE   https: doi.org 10.1371 journal.pone.0237749 August 18, 2020 8   37 PLOS ONE A systematic review of fuzzing based on machine learning techniques Table 3 lists the corresponding research articles in each category. However, the current seed selection strategies (e.g., using standard benchmarks, crawling from the Internet, and using existing POC samples) have shortcomings. For example, they require more time to acquire the seed set, and the execution effect of selected seeds is almost the same as that of randomly selected seeds  100 . Distribution of research literature based on machine learning for different steps of fuzzing. Step Studies Seed file generation SP3, SP6, SP12, SP31, SP37, SP44 Testcase generation SP2, SP4, SP10, SP11, SP15, SP18, SP20, SP21, SP24, SP25, SP26, SP27, SP28, SP29, SP32, SP33, SP34, SP36, SP39, SP40, SP42, SP43 Testcase filtering SP5, SP14, SP16, SP38, SP41 Mutation operator SP1, SP9, SP13, SP17, SP19, SP22, SP30 selection Exploitability analysis SP7, SP8, SP23, SP35 https: doi.org 10.1371 journal.pone.0237749.t003 PLOS ONE   https: doi.org 10.1371 journal.pone.0237749 August 18, 2020 9   37 PLOS ONE A systematic review of fuzzing based on machine learning techniques Mutation based testcase generation The most critical problem to answer in mutation based testcase generation is to determine where the input samples mutate and how to mutate. Machine learning is mainly used to automatically learn the syntax from a collection of corpus that conforms to the input grammar rules. According to the type of input format of the target program learned in different papers, we summarized the research work of generation based testcase generation from the three dimen  sions of file format, protocol, and compilers, respectively. PLOS ONE   https: doi.org 10.1371 journal.pone.0237749 August 18, 2020 10   37 PLOS ONE A systematic review of fuzzing based on machine learning techniques The first dimension is the file format. However, the complex file format con  tains both textual and non textual data. Finally, the new test  case will be generated by assembling the generated textual data with the mutated non textual data. For using PLOS ONE   https: doi.org 10.1371 journal.pone.0237749 August 18, 2020 11   37 PLOS ONE A systematic review of fuzzing based on machine learning techniques code coverage as a filter, Gong et al. PLOS ONE   https: doi.org 10.1371 journal.pone.0237749 August 18, 2020 12   37 PLOS ONE A systematic review of fuzzing based on machine learning techniques Exploitability analysis Vulnerability exploitability means the possibility that vulnerability is exploited by an attacker. Analysis of machine learning based fuzzing model In the current machine learning based fuzzing research work, there is less work to compare the performance of various algorithms systematically. This section summarizes the knowledge of the machine learning model used in fuzzing. Statistical results demonstrate that each traditional machine PLOS ONE   https: doi.org 10.1371 journal.pone.0237749 August 18, 2020 13   37 PLOS ONE A systematic review of fuzzing based on machine learning techniques Table 4. Distribution of machine learning arithmetics for fuzzing. PLOS ONE   https: doi.org 10.1371 journal.pone.0237749 August 18, 2020 14   37 PLOS ONE A systematic review of fuzzing based on machine learning techniques The length of input and output sequences of the seq2seq model is variable, which can use the input of fuzzing as text data effectively to learn local or global syntax information. Pre processing methods Due to the different types of PUT, the input format is quite different, such as text, pictures, video, network data packets, and program code. However, the input for machine learning is typically vector data, so original input data cannot be fed into the machine learning algorithms directly. Table 5 summarizes the data preprocessing methods commonly used for fuzz testing. Pre processing methods for machine learning techniques in fuzzing. Pre processing Description Method Studies Program analysis The extracted information is transformed into SP8, SP25, SP27, SP34, SP37, SP39, SP40, vectors by static or dynamic analysis. SP35, SP38, SP41, SP43 https: doi.org 10.1371 journal.pone.0237749.t005 PLOS ONE   https: doi.org 10.1371 journal.pone.0237749 August 18, 2020 15   37 PLOS ONE A systematic review of fuzzing based on machine learning techniques Datasets The performance of machine learning is primarily influenced by the training data. The dataset consists of four programs from the GNU Coreutils suite: uniq, base64, md5sum, and who, PLOS ONE   https: doi.org 10.1371 journal.pone.0237749 August 18, 2020 16   37 PLOS ONE A systematic review of fuzzing based on machine learning techniques which are injected with 28, 44, 57, and 2265 errors with unique IDs, respectively, with some unlabeled errors. Evaluation metrics The performance evaluation of the fuzzing methods based on machine learning technology can be divided into two aspects: the evaluation of the performance of the machine learning model and the evaluation of the capability of vulnerability detection. Table 5 summarizes the metrics and detailed information used to evaluate the machine learning model in fuzzing. According to the statistics in Table 6, the most commonly used performance metrics are Accu  racy, which are closely followed by Precision, Recall, Loss, FPR, and F measure. Table 7 summarizes the metrics and details of the vulnerability detection performance that have been used to evaluate the fuzzing method based on machine learning technology. However, the fuzzing method based on machine learning has model training, feature extraction, and other steps, so efficiency is also used in much literature. Evaluation metrics and details for machine learning models in fuzzing. Performance metric Description Accuracy It is the proportion of the total number of correct predictions amongst the total number of correct as well as incorrect predictions. Evaluation metrics and details for fuzzers based on machine learning. https: doi.org 10.1371 journal.pone.0237749.t007 Hyperparameters setting In the implementation of the machine learning model, the value of hyperparameters is not obtained by training but requires artificial settings before training. However, the advantages and disadvan  tages of different activation functions are different, such as sigmoid input range between  0, 1 , Table 8. Analysis of hyperparameters setting of machine learning models for fuzzing. Learning rate 0.0001, 0.0005, 0.001, 0.002, 0.02, 0.1 0.001 was used the most https: doi.org 10.1371 journal.pone.0237749.t008 PLOS ONE   https: doi.org 10.1371 journal.pone.0237749 August 18, 2020 18   37 PLOS ONE A systematic review of fuzzing based on machine learning techniques but there are "sigmoid saturate and kill gradients" and not "zero centered" problems  121 . Performance evaluation of fuzzing model based on machine learning The performance evaluation of machine learning based fuzzing model is divided into two parts. However, the detailed parameter settings of the experi  ments are not given explicitly in many works of literature, and the experimental codes are not open sourced. Performance evaluation of machine learning arithmetics In this section, we summarize the results of the machine learning arithmetics. The results in Section 3.4.5 demonstrate that Accuracy, Precision, Recall, and Loss are the most frequently used performance measures in the selected research literature. The results are manifested in Figs 3 6. The main reason for the occurrence of the values of these metrics in these two models is that the features selected in the paper are not highly correlated with vulnerabilities, so they cannot be effectively used as the prediction of exploitable samples and vulnerability samples. However, the lower value of the performance metrics Loss indicates the higher robustness of the model. The data in this part of the model may be biased, but in PLOS ONE   https: doi.org 10.1371 journal.pone.0237749 August 18, 2020 19   37 PLOS ONE A systematic review of fuzzing based on machine learning techniques Fig 3. https: doi.org 10.1371 journal.pone.0237749.g003 the published experimental environment, the values of these performance metrics indicate that the machine learning model for fuzzing has reasonable predictive power. Performance evaluation of vulnerability detection In the fuzz testing, there exist some challenges such as how to mutate and generate input seed files, how to increase coverage rate, and how to pass the validation effectively. This section summarizes the experimental results of the fuzzing tools based on machine learning and evaluates them from the aspects of code coverage, unique code paths, unique crashes or bugs, pass rate, and efficiency. Machine learning based fuzzer PLOS ONE   https: doi.org 10.1371 journal.pone.0237749 August 18, 2020 20   37 PLOS ONE A systematic review of fuzzing based on machine learning techniques Fig 4. https: doi.org 10.1371 journal.pone.0237749.g004 compared to the traditional AFL and its improved version, NEUZZ (SP28) has a fourfold increase in coverage compared to baseline AFL, with a minimum of 1.26  improvement. However, there are also some models (SP25, SP34) that do not improve or even worse in terms of code coverage than tradi  tional fuzzers, but this is only a few phenomena. Table 10 summarizes the results of crash and bug PLOS ONE   https: doi.org 10.1371 journal.pone.0237749 August 18, 2020 21   37 PLOS ONE A systematic review of fuzzing based on machine learning techniques Fig 5. https: doi.org 10.1371 journal.pone.0237749.g005 experiments in different works of literature. Machine learning based fuzzers have been found more crashes or bugs than traditional fuzzers, especially the vul  nerability oriented V fuzz (SP25) is found 3872,14279,14213 more crashes and bugs than baseline Vuzzer, AFL and AFLFast respectively. The main reason was that IUST DeepFuzz did not combine the feedback in the testcase muta  tion with the fuzzing process, so it could not effectively explore more in depth code to find a crash or bug. The first line lists the four programs PLOS ONE   https: doi.org 10.1371 journal.pone.0237749 August 18, 2020 22   37 PLOS ONE A systematic review of fuzzing based on machine learning techniques Fig 6. https: doi.org 10.1371 journal.pone.0237749.g006 in LAVA M. However, there is a threat to the validity of this con  clusion. However, the Montage (SP42) sample had a 5.2  lower pass rate than the random selection method, with only 58 . Coverage category Fuzzing model Baselines Results basic block coverage SP21 AFL   2.26  a Augmented AFL  7.73  Learn Fuzz  56  SP4 AFL  1.26  SP25 VUzzer 0 SP30 GCC test suite baseline  37.14  SP37 AFL  2.48  SP36 boofuzz  2.65  line coverage SP19 LibFuzzer  2.5 times SP6 Crawl AFL  20  SP29 Csmith  6.69  SP24 Learn Fuzz  0.23  DeepSmith  0.52  relative coverage SP14 FidgetyAFL  11  Batched FidgetyAFL  13  Random Batched FidgetyAFL  6  SP13 AFL  20  FidgetyAFL  11  FaireFuzz  7  function coverage SP6 Crawl AFL  15  SP29 Csmith  2.26  SP24 Learn Fuzz  0.46  DeepSmith  0.9  instruction coverage SP2 Normal sample execution  1  SP10 Learn Fuzz  0.11  SP34 Unif  16  Expert  8  Echidna  24  branch coverage SP28 AFL  4 times AFLFast  2.8 times VUzzer  64 times KleeFL  5 times AFL laf intel  54 times RNN  5.7 times SP29 Csmith  2.36  SP44 QSYM  10  Remarks: The value after the symbol " " in the result column indicates the increased coverage of the fuzzing models based on machine learning compared to different baselines. https: doi.org 10.1371 journal.pone.0237749.t009 A systematic review of fuzzing based on machine learning techniques PLOS ONE   https: doi.org 10.1371 journal.pone.0237749 August 18, 2020 24   37 PLOS ONE Table 10. https: doi.org 10.1371 journal.pone.0237749.t010 A systematic review of fuzzing based on machine learning techniques PLOS ONE   https: doi.org 10.1371 journal.pone.0237749 August 18, 2020 25   37 PLOS ONE satisfies the state transition relationship of industrial protocol. For example, the time that it needs to find a given number of crashes and hangs, the number that test samples executed per sec  ond, and the time that it takes to execute the same test samples. Performance metrics in execution time, machine learning based fuzzers are significantly more efficient in execution than traditional fuzzers or common auxiliary methods, with at least 5  (SP5). The main rea  son is that the fuzzer based on machine learning reduced the execution of a large number of invalid samples. However, there are also cases where execution time is more expensive, A s Fuzzer is 4  slower than Kitty Fuzzer, and Neufuzz (SP31) is 8  slower than PTfuzz  131  due to the need for path recovery, but these machine learn based fuzzers take less time than the improved baseline fuzzer. The results of Skyfire are not summarized in Table 11 because it is not compared to other models, but its execution time and generation time are Table 11. base64 md5sum uniq who  Bugs 44 57 28 2136 AFL 0 0 9 1 VUzzer 17     27 50 FUZZER 7 2 7 0 SES 9 0 0 18 Steelix 43 28 24 194 Angora 48 57 29 1,541 AFL laf intel 42 49 24 17 InsFuzz 48 38 11 802 T fuzz 43 49 26 63 REDQUEEN 44 57 28 2134 DigFuzz 48 59 28 167 SP28 48 60 29 1,582 SP31 6     5 8 SP13 31 1 0 106 SP25 27     28 62 SP39 18     5 40 https: doi.org 10.1371 journal.pone.0237749.t011 A systematic review of fuzzing based on machine learning techniques PLOS ONE   https: doi.org 10.1371 journal.pone.0237749 August 18, 2020 26   37 PLOS ONE Table 12. A systematic review of fuzzing based on machine learning techniques Efficiency Execution time Generated time Fuzzing model SP5 SP31 SP17 SP15 SP43 SP34 SP39 SP41 SP38 SP35 SP3 SP9 SP12 SP15 Baselines AFL QAFL PTFuzz Random selection CLSmith Kitty Fuzzer Peach Fuzzer Unif Echidna Expert VUzzer AFLGo Random Random Random reinitialization LSTM Random Peachset AFL cmin Hostset Random selection AFL result CLSmith Results  5   2.5 times  8    11.3   4.46 times  4   46   75   17   99 times  41   5.4 times  21   30   14.23   60.72   6 times  41 times  14 times  2000 times  480 times  480 times  2.45 times Remarks: 1) the value after the symbol " " indicates the efficiency improvement of the fuzzing models based on machine learning compared with different baselines.2) the value after the symbol " " indicates the decrease of the efficiency of the fuzzing models based on machine learning compared with different baselines. https: doi.org 10.1371 journal.pone.0237749.t012 within the efficient range of 920, 938, and 1008 XSL, XML, and JavaScript per second, respec  tively. For the first and second conditions, the fuzzing pro  cess is sufficient because the fuzzing can produce a large number of test samples and crash samples, which can be labeled during sample generation (e.g., whether code coverage increases during execution). Since many of the input files of fuzzing can be treated directly as textual PLOS ONE   https: doi.org 10.1371 journal.pone.0237749 August 18, 2020 27   37 PLOS ONE A systematic review of fuzzing based on machine learning techniques data, natural language processing provide an effective means of converting various data into vectors. The satisfaction of these prior conditions and the advantages of machine learning have led to rapid growth in the research of machine learning based fuzzing. Machine learning techniques have been used in the five stages of fuzzing: seed file generation, testcase generation, testcase filtering, mutation operator selection, and exploitability analysis. Traditional Machine learning, deep learning, and reinforcement learning have been used in fuzzing. PLOS ONE   https: doi.org 10.1371 journal.pone.0237749 August 18, 2020 28   37 PLOS ONE A systematic review of fuzzing based on machine learning techniques RQ5: Which datasets are used for training and evaluating? According to the statistical analysis of the existing literature, the average value of the machine learning arithmetics for fuzzing in the four measurement dimensions of accuracy, precision, recall, and loss reaches 0.93, 0,952, 0.823, 0.305, respectively. In the dimension of code coverage, the fuzzers based on machine learning was improved by an average of 17.3  on the code coverage compared to the baseline (excluding SP28 results). PLOS ONE   https: doi.org 10.1371 journal.pone.0237749 August 18, 2020 29   37 PLOS ONE A systematic review of fuzzing based on machine learning techniques 2. In the dimension of unique code paths, the machine learning based fuzzers have a mini  mum increase of 6.16  and a maximum of 2 times, an average increase of 56.83  com  pared to the baseline. In the dimension of unique crashes or bugs, the machine learning based fuzzers can find more unique crashes and bugs on the real world more than the baseline, but the results of the bugs found on the LAVA M dataset are poor. Traditional fuzzers have better pro  gram analysis capabilities than fuzzers based on machine learning, so they can bypass more complicated magic byte check to trigger these bugs. In the dimension of pass rate, the minimum pass rate of testcases generated by machine learning based fuzzers can reach 58 , the highest can reach 99.99 , and the average pass rate is 83.95 . In the dimension of efficiency, the fuzzers based on machine learning have a minimum exe  cution time improvement of 5  and a maximum of 99 times compared to the baseline, and a minimum increase of 14.23  and a maximum of 2000 times in testcase generation time. The results depict that machine learning has an excellent predictive capability for fuzzing. Finally, the capability of vulnerability discovery for the machine learning based fuzzer is analyzed by comparing it with the traditional fuzzer. The goal of directed grey box fuzzing is to check whether a piece of potentially buggy code PLOS ONE   https: doi.org 10.1371 journal.pone.0237749 August 18, 2020 31   37 PLOS ONE A systematic review of fuzzing based on machine learning techniques really contains a bug. In: Proceedings of the 31st IEEE  ACM International Conference on Automated Software Engineering. In: Proceedings of the Fourth ACM International Workshop on Security and Privacy Analytics ACM. In: Proceedings of the Sixth ACM Conference on Data and Application Security and Privacy. PLOS ONE   https: doi.org 10.1371 journal.pone.0237749 August 18, 2020 32   37 PLOS ONE A systematic review of fuzzing based on machine learning techniques 17. In: Proceedings of the ACM Conference on Computer and Communications Security. In: Proceedings of the 2008 ACM SIGPLAN conference on Programming language design and implementation. In: Proceedings of the 5th ACM Conference on Data and Application Security and Privacy. In: Proceedings of the 8th USENIX conference on Operating sys  tems design and implementation. In: Proceedings 2015 Network and Distributed Sys  tem Security Symposium. In: Proceedings of the sixth conference on Computer systems. PLOS ONE   https: doi.org 10.1371 journal.pone.0237749 August 18, 2020 33   37 PLOS ONE A systematic review of fuzzing based on machine learning techniques 43. In: Proceedings of the 15th ACM International Conference on Computing Frontiers. PLOS ONE   https: doi.org 10.1371 journal.pone.0237749 August 18, 2020 34   37 PLOS ONE A systematic review of fuzzing based on machine learning techniques 67. In: Proceedings—2019 IEEE 12th International Conference on Software Testing, Verification and Validation, ICST 2019. In: Proceedings 2019 Network and Dis  tributed System Security Symposium. In: Proceedings of the 41st International Conference on Software Engineering: Companion Proceedings. Introduction to reinforcement learning. https: doi.org 10.1109 72.788640 PMID: 18252602 Neal RM. Machine learning and data mining. In: Proceedings of the 25th international conference on Machine learning. PLOS ONE   https: doi.org 10.1371 journal.pone.0237749 August 18, 2020 35   37 PLOS ONE A systematic review of fuzzing based on machine learning techniques 92. In: Proceedings of the 9th EAI International Conference on Bio inspired Information and Communica  tions Technologies (formerly BIONETICS). In: Proceedings of the 16th interna  tional conference on World Wide Web. In: Proceedings of the 20th National Information Systems Security Conference; 1997. p. 366 380. In: Proceedings of the 24th annual international ACM SIGIR conference on Research and development in information retrieval; 2001. p. 241 249. PLOS ONE   https: doi.org 10.1371 journal.pone.0237749 August 18, 2020 36   37 PLOS ONE A systematic review of fuzzing based on machine learning techniques 117. In: Proceedings of the 32nd ACM SIGPLAN conference on Programming language design and implementation—PLDI  11. In: Proceedings 2019 Network and Distributed System Security Symposium. PLOS ONE   https: doi.org 10.1371 journal.pone.0237749 August 18, 2020 37   37 PLOS ONE